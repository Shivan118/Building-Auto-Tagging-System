{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_questions = pd.read_hdf('auto_tagging_data_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning?</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=\"http://anyall.org/\"&gt;Brendan O'Connor&lt;/a&gt; entitled &lt;a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\"&gt;\"Statistics vs. Mach...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demographic census with some validation and calibration techniques?&lt;/p&gt;\\n\\n&lt;p&gt;Some of the concerns:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Census blocks vary in sizes as rural\\n...</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain English</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?&lt;/p&gt;\\n</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values in statistical tests?</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....</td>\n",
       "      <td>[hypothesis-testing, t-test, p-value, interpretation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not mean causation</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:&lt;/p&gt;\\n\\n&lt;ol&gt;\\n&lt;li&gt;number of storks and birth ...</td>\n",
       "      <td>[correlation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                               Title  \\\n",
       "0   6                  The Two Cultures: statistics vs. machine learning?   \n",
       "1  21                                      Forecasting demographic census   \n",
       "2  22                 Bayesian and frequentist reasoning in plain English   \n",
       "3  31  What is the meaning of p values and t values in statistical tests?   \n",
       "4  36          Examples for teaching: Correlation does not mean causation   \n",
       "\n",
       "                                                                                                                                                                                                      Body  \\\n",
       "0  <p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Mach...   \n",
       "1  <p>What are some of the ways to forecast demographic census with some validation and calibration techniques?</p>\\n\\n<p>Some of the concerns:</p>\\n\\n<ul>\\n<li>Census blocks vary in sizes as rural\\n...   \n",
       "2                                                                               <p>How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?</p>\\n   \n",
       "3  <p>After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests....   \n",
       "4  <p>There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:</p>\\n\\n<ol>\\n<li>number of storks and birth ...   \n",
       "\n",
       "                                                    Tags  \n",
       "0                                     [machine-learning]  \n",
       "1                                          [forecasting]  \n",
       "2                                             [bayesian]  \n",
       "3  [hypothesis-testing, t-test, p-value, interpretation]  \n",
       "4                                          [correlation]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine title and body\n",
    "df_questions['Text'] = df_questions[\"Title\"] + \" \" + df_questions[\"Body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove html tags and url links\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # remove everything alphabets\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
    "    # remove whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions['Text'] = df_questions['Text'].apply(lambda x: clean_text(x))\n",
    "df_questions['Text'] = df_questions['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69866</th>\n",
       "      <td>23873</td>\n",
       "      <td>how does sas calculate exact non parametric statistics i have written c code to calculate the exact jonckheere terpstra distribution and therefore p value by enumerating all the possible combinati...</td>\n",
       "      <td>[nonparametric]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45722</th>\n",
       "      <td>93751</td>\n",
       "      <td>goodness of fit of a sur model i know that mcelroy r is a measure of goodness of fit for seemingly unrelated regressions sur models but how can one judge that the estimated equations are well fit ...</td>\n",
       "      <td>[regression, goodness-of-fit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8536</th>\n",
       "      <td>212630</td>\n",
       "      <td>analysing categorical variables in r with chisq test with small no expected values i was wondering if anyone could help me with analysing data in r i am working with transplant data i am looking t...</td>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30563</th>\n",
       "      <td>165222</td>\n",
       "      <td>matrix differentiation i know the function d expression x x will give me the derivative of x which is x whoever when i am trying to take the derivative of the function exp b x using the same funct...</td>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73142</th>\n",
       "      <td>22760</td>\n",
       "      <td>how many possibilities is there to choose boxes of given size we have a collection of boxes each is one of four sizes evenly distributed of each sizea sizeb sizec sized our person is presented wit...</td>\n",
       "      <td>[probability, distributions]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  \\\n",
       "69866   23873   \n",
       "45722   93751   \n",
       "8536   212630   \n",
       "30563  165222   \n",
       "73142   22760   \n",
       "\n",
       "                                                                                                                                                                                                          Text  \\\n",
       "69866  how does sas calculate exact non parametric statistics i have written c code to calculate the exact jonckheere terpstra distribution and therefore p value by enumerating all the possible combinati...   \n",
       "45722  goodness of fit of a sur model i know that mcelroy r is a measure of goodness of fit for seemingly unrelated regressions sur models but how can one judge that the estimated equations are well fit ...   \n",
       "8536   analysing categorical variables in r with chisq test with small no expected values i was wondering if anyone could help me with analysing data in r i am working with transplant data i am looking t...   \n",
       "30563  matrix differentiation i know the function d expression x x will give me the derivative of x which is x whoever when i am trying to take the derivative of the function exp b x using the same funct...   \n",
       "73142  how many possibilities is there to choose boxes of given size we have a collection of boxes each is one of four sizes evenly distributed of each sizea sizeb sizec sized our person is presented wit...   \n",
       "\n",
       "                                Tags  \n",
       "69866                [nonparametric]  \n",
       "45722  [regression, goodness-of-fit]  \n",
       "8536                             [r]  \n",
       "30563                            [r]  \n",
       "73142   [probability, distributions]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions[['Id', 'Text', 'Tags']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Text to Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81956"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81957"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique words count\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df_questions['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the two cultures statistics vs machine learning last year i read a blog post from brendan o connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to this simon blomberg from r s fortunes package to paraphrase provocatively machine learning is statistics minus any checking of models and assumptions brian d ripley about the difference between machine learning and statistics user vienna may season s greetings andrew gelman in that case maybe we should get rid of checking of models and assumptions more often then maybe we d be able to solve some of the problems that the machine learning people can solve but we can t there was also the statistical modeling the two cultures paper by leo breiman in which argued that statisticians rely too heavily on data modeling and that machine learning techniques are making progress by instead relying on the predictive accuracy of models has the statistics field changed over the last decade in response to these critiques do the two cultures still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines \n",
      "\n",
      "[1, 59, 9730, 255, 315, 482, 256, 577, 277, 2, 333, 3, 2733, 374, 36, 24159, 665, 20232, 9413, 255, 315, 482, 256, 12412, 11, 2734, 60, 5, 1, 441, 74, 1, 59, 2265, 3603, 3384, 5009, 18773, 4, 12, 6933, 50267, 36, 45, 34, 38034, 250, 4, 14051, 50268, 482, 256, 6, 255, 2548, 68, 1771, 5, 132, 7, 691, 9140, 70, 9568, 89, 1, 167, 74, 482, 256, 7, 255, 600, 21877, 264, 1580, 34, 10105, 3603, 3384, 8, 11, 143, 580, 54, 83, 103, 3655, 5, 1771, 5, 132, 7, 691, 92, 726, 81, 580, 54, 70, 19, 375, 4, 588, 60, 5, 1, 597, 11, 1, 482, 256, 320, 28, 588, 31, 54, 28, 17, 43, 97, 105, 1, 235, 772, 1, 59, 9730, 433, 55, 16689, 7210, 8, 47, 6113, 11, 3184, 3258, 427, 3024, 21, 13, 772, 7, 11, 482, 256, 865, 18, 912, 3570, 55, 424, 6334, 21, 1, 785, 406, 5, 132, 100, 1, 255, 1056, 1670, 186, 1, 577, 8085, 8, 234, 4, 94, 15913, 48, 1, 59, 9730, 330, 1223, 33, 100, 255, 6392, 4, 16690, 482, 256, 865, 164, 25, 478, 886, 7, 855, 270, 2100]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "print(df_questions['Text'][i], '\\n'), print(sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find right maximum length for the sequences__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = []\n",
    "\n",
    "for i in sequences:\n",
    "    seq_lengths.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th percentile:  97.0\n",
      "40th percentile:  116.0\n",
      "50th percentile:  137.0\n",
      "60th percentile:  162.0\n",
      "70th percentile:  193.0\n",
      "80th percentile:  238.0\n",
      "90th percentile:  320.0\n",
      "95th percentile:  411.0\n",
      "99th percentile:  678.0\n"
     ]
    }
   ],
   "source": [
    "print(\"30th percentile: \", pd.Series(seq_lengths).quantile(0.3))\n",
    "print(\"40th percentile: \", pd.Series(seq_lengths).quantile(0.4))\n",
    "print(\"50th percentile: \", pd.Series(seq_lengths).quantile(0.5))\n",
    "print(\"60th percentile: \", pd.Series(seq_lengths).quantile(0.6))\n",
    "print(\"70th percentile: \", pd.Series(seq_lengths).quantile(0.7))\n",
    "print(\"80th percentile: \", pd.Series(seq_lengths).quantile(0.8))\n",
    "print(\"90th percentile: \", pd.Series(seq_lengths).quantile(0.9))\n",
    "print(\"95th percentile: \", pd.Series(seq_lengths).quantile(0.95))\n",
    "print(\"99th percentile: \", pd.Series(seq_lengths).quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 125\n",
    "\n",
    "# padding\n",
    "padded_seq = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions['Tags'])\n",
    "y = multilabel_binarizer.transform(df_questions['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76365, 125), (76365, 100))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seq.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(padded_seq, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(2000, 128, input_length = max_length))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Conv1D(300, 3, padding = 'valid', activation = \"relu\", strides = 1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100, activation = \"sigmoid\"))\n",
    "#model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 125, 128)          256000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 123, 300)          115500    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "=================================================================\n",
      "Total params: 401,600\n",
      "Trainable params: 401,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "             EarlyStopping(patience=3),\n",
    "             ModelCheckpoint(filepath='model-conv1d_v1.h5', save_best_only=True)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54982 samples, validate on 6110 samples\n",
      "Epoch 1/10\n",
      "54982/54982 [==============================] - 38s 689us/step - loss: 0.0512 - acc: 0.9839 - val_loss: 0.0535 - val_acc: 0.9835\n",
      "Epoch 2/10\n",
      "54982/54982 [==============================] - 38s 693us/step - loss: 0.0503 - acc: 0.9841 - val_loss: 0.0531 - val_acc: 0.9834\n",
      "Epoch 3/10\n",
      "54982/54982 [==============================] - 38s 691us/step - loss: 0.0495 - acc: 0.9842 - val_loss: 0.0528 - val_acc: 0.9835\n",
      "Epoch 4/10\n",
      "54982/54982 [==============================] - 38s 692us/step - loss: 0.0488 - acc: 0.9844 - val_loss: 0.0526 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "54982/54982 [==============================] - 38s 691us/step - loss: 0.0481 - acc: 0.9846 - val_loss: 0.0524 - val_acc: 0.9836\n",
      "Epoch 6/10\n",
      "54982/54982 [==============================] - 39s 712us/step - loss: 0.0474 - acc: 0.9847 - val_loss: 0.0521 - val_acc: 0.9836\n",
      "Epoch 7/10\n",
      "54982/54982 [==============================] - 38s 694us/step - loss: 0.0468 - acc: 0.9849 - val_loss: 0.0522 - val_acc: 0.9835\n",
      "Epoch 8/10\n",
      "54982/54982 [==============================] - 38s 696us/step - loss: 0.0463 - acc: 0.9850 - val_loss: 0.0520 - val_acc: 0.9835\n",
      "Epoch 9/10\n",
      "54982/54982 [==============================] - 39s 703us/step - loss: 0.0457 - acc: 0.9851 - val_loss: 0.0521 - val_acc: 0.9835\n",
      "Epoch 10/10\n",
      "54982/54982 [==============================] - 39s 704us/step - loss: 0.0452 - acc: 0.9852 - val_loss: 0.0520 - val_acc: 0.9834\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Performane Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the code below to load the saved model\n",
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15273, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set threshold to 0.45\n",
    "preds_int = (preds >= 0.45).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5107349376896506"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# calculate F1 score\n",
    "f1_score(y_val, preds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model-conv1d_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = q.lower()\n",
    "    q_seq = tokenizer.texts_to_sequences([q])\n",
    "    q_seq_padded = pad_sequences(q_seq, maxlen=300)\n",
    "    q_pred = model.predict(q_seq_padded)\n",
    "    q_pred = (q_pred >= 0.3).astype(int)\n",
    "    \n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data-visualization', 'r', 'regression')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give new question\n",
    "new_q = \"Regression line in ggplot doesn't match computed regression Im using R and created a chart using ggplot2. I then create a regression so I can make some predicitions I pass my data frame of to the predict function predict(regression, Measures) I'd expect the predictions to be the same as if I used the regression line on the chart, but they aren't the same. Why would this be the case? Is there a setting in ggplot or is my expectation incorrect?\"\n",
    "\n",
    "# get tags\n",
    "infer_tags(new_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
